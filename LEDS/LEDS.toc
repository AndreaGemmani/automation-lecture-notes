\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}%
\contentsline {section}{\numberline {1.1}What is a system?}{5}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Learning modesl from data}{6}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}Types of learning}{6}{section.1.2}%
\contentsline {section}{\numberline {1.3}fields related to learning from data}{6}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}System identification}{6}{subsection.1.3.1}%
\contentsline {subsubsection}{Grey box approach}{7}{section*.2}%
\contentsline {section}{\numberline {1.4}Learning steps}{7}{section.1.4}%
\contentsline {chapter}{\numberline {2}Stochastic Processes}{9}{chapter.2}%
\contentsline {section}{\numberline {2.1}stationary stochastic processes}{9}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}cross-correlation and cross-covariance}{9}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}vector stochastic processes}{9}{section.2.2}%
\contentsline {section}{\numberline {2.3}gaussian processes}{9}{section.2.3}%
\contentsline {section}{\numberline {2.4}white processes}{9}{section.2.4}%
\contentsline {chapter}{\numberline {3}Stochastic models}{11}{chapter.3}%
\contentsline {section}{\numberline {3.1}Matlab stuff}{11}{section.3.1}%
\contentsline {chapter}{\numberline {4}Estmation problem}{13}{chapter.4}%
\contentsline {chapter}{\numberline {5}Linear regression}{15}{chapter.5}%
\contentsline {section}{\numberline {5.1}The Least Squares Method}{15}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Geometrical interpretation of the LS estimate}{16}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Statistical properties of the LS estimator}{16}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}LS estimation fo ARX models}{17}{subsection.5.1.3}%
\contentsline {subsubsection}{Identifiablity}{17}{section*.3}%
\contentsline {subsubsection}{Statistical properties}{17}{section*.4}%
\contentsline {subsection}{\numberline {5.1.4}ARX optimal (one step ahead) predictor}{18}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}LS estimation of AR models}{18}{subsection.5.1.5}%
\contentsline {section}{\numberline {5.2}Recursive least squares}{18}{section.5.2}%
\contentsline {subsubsection}{RLS I}{19}{section*.5}%
\contentsline {subsubsection}{RLS II}{20}{section*.6}%
\contentsline {subsubsection}{Matrix inversion lemma (Woodbury identity)}{20}{section*.7}%
\contentsline {subsubsection}{RLS III}{20}{section*.8}%
\contentsline {subsubsection}{RLS IV}{20}{section*.9}%
\contentsline {subsubsection}{Initialization}{21}{section*.10}%
\contentsline {subsection}{\numberline {5.2.1}Asymptotic behaviour of the RLS algorithm}{21}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Recursive wighted least squares}{21}{subsection.5.2.2}%
\contentsline {subsubsection}{RWLS I}{21}{section*.11}%
\contentsline {chapter}{\numberline {6}Prediction error methods}{23}{chapter.6}%
\contentsline {subsection}{\numberline {6.0.1}The Newton-Raphson Algorithm}{25}{subsection.6.0.1}%
\contentsline {subsection}{\numberline {6.0.2}The Gauss-Newton Method}{25}{subsection.6.0.2}%
\contentsline {subsection}{\numberline {6.0.3}Identification of ARMAX models}{26}{subsection.6.0.3}%
\contentsline {subsection}{\numberline {6.0.4}Identification of ARARX models}{26}{subsection.6.0.4}%
\contentsline {subsection}{\numberline {6.0.5}Statistical properties of PEM estimators}{26}{subsection.6.0.5}%
\contentsline {subsection}{\numberline {6.0.6}MISO ARX models}{27}{subsection.6.0.6}%
\contentsline {chapter}{\numberline {7}Statistical hypothesis testing}{29}{chapter.7}%
\contentsline {chapter}{\numberline {8}Model complexity selection}{31}{chapter.8}%
\contentsline {section}{\numberline {8.1}The F-test}{31}{section.8.1}%
\contentsline {section}{\numberline {8.2}The final prediction error (FPE) criterion}{32}{section.8.2}%
\contentsline {section}{\numberline {8.3}Criteria with complexity terms}{33}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}Akaike information criterien (AIC)}{33}{subsection.8.3.1}%
\contentsline {subsubsection}{Minimum description lenght (MDL) criterion}{33}{section*.12}%
\contentsline {chapter}{\numberline {9}Model assesment (validation)}{35}{chapter.9}%
\contentsline {section}{\numberline {9.1}Whiteness test}{35}{section.9.1}%
\contentsline {section}{\numberline {9.2}Test of cross-correlation}{36}{section.9.2}%
\contentsline {chapter}{\numberline {10}Maximum likelihood estimation}{37}{chapter.10}%
\contentsline {section}{\numberline {10.1}the gaussian case}{37}{section.10.1}%
\contentsline {subsection}{\numberline {10.1.1}the Cram√©r-Rao lower bound}{38}{subsection.10.1.1}%
\contentsline {chapter}{\numberline {11}Classification: probabilistic models}{39}{chapter.11}%
\contentsline {section}{\numberline {11.1}The Bayes classifier}{39}{section.11.1}%
\contentsline {section}{\numberline {11.2}Logistic regression}{40}{section.11.2}%
\contentsline {subsubsection}{How to classify a new input $u(t)$?}{41}{section*.13}%
\contentsline {subsection}{\numberline {11.2.1}The gradient descent algorithm}{41}{subsection.11.2.1}%
\contentsline {subsubsection}{Stochastic gradient descent}{42}{section*.14}%
\contentsline {subsubsection}{Confusion matrix}{42}{section*.15}%
\contentsline {subsection}{\numberline {11.2.2}Multiclass problems}{42}{subsection.11.2.2}%
\contentsline {subsection}{\numberline {11.2.3}Dealing with nonlinear boundaries}{43}{subsection.11.2.3}%
\contentsline {subsection}{\numberline {11.2.4}Linear discriminant analysis}{43}{subsection.11.2.4}%
\contentsline {subsection}{\numberline {11.2.5}Gaussian class densities with commmon covariance matrix}{44}{subsection.11.2.5}%
\contentsline {subsubsection}{Multiclass problem}{44}{section*.16}%
\contentsline {subsection}{\numberline {11.2.6}Gaussian class denisities with different covariance matrices}{44}{subsection.11.2.6}%
\contentsline {chapter}{\numberline {12}Classification: deterministic models}{45}{chapter.12}%
\contentsline {subsection}{\numberline {12.0.1}Separating hyperplanes}{46}{subsection.12.0.1}%
\contentsline {subsection}{\numberline {12.0.2}the maximum margin classifier}{46}{subsection.12.0.2}%
\contentsline {section}{\numberline {12.1}Constrained optimization problems: the Lagrange multipliers}{46}{section.12.1}%
\contentsline {subsubsection}{Finding the maximum margin classifier by using the Lagrange multipliers}{48}{section*.17}%
\contentsline {section}{\numberline {12.2}Support vector machine}{49}{section.12.2}%
\contentsline {subsection}{\numberline {12.2.1}Dealing with nonlinear boundaries: the kernel trick}{51}{subsection.12.2.1}%
\contentsline {subsubsection}{How does it work?}{51}{section*.18}%
\contentsline {subsection}{\numberline {12.2.2}Multiclass problems}{52}{subsection.12.2.2}%
\contentsline {subsubsection}{One-vs-all approach}{52}{section*.19}%
\contentsline {subsubsection}{One-vs-one approach}{52}{section*.20}%
\contentsline {chapter}{\numberline {13}Regularization}{53}{chapter.13}%
\contentsline {section}{\numberline {13.1}Regularized least squares: the Ridge regression}{53}{section.13.1}%
\contentsline {subsubsection}{Alternative formulation for Ridge regression}{55}{section*.21}%
\contentsline {chapter}{\numberline {14}Optimal estimation of random signals}{57}{chapter.14}%
\contentsline {subsubsection}{The fundamental theorem of estimation theory}{57}{section*.22}%
\contentsline {subsubsection}{The innovation sequence}{58}{section*.23}%
\contentsline {section}{\numberline {14.1}the Kalman filter}{58}{section.14.1}%
\contentsline {subsection}{\numberline {14.1.1}Deterministic state space models: the Luenberger observer}{58}{subsection.14.1.1}%
\contentsline {subsubsection}{Luenberger observer}{58}{section*.24}%
\contentsline {subsection}{\numberline {14.1.2}Stochastic state space models}{58}{subsection.14.1.2}%
\contentsline {subsection}{\numberline {14.1.3}Kalman predictor form}{58}{subsection.14.1.3}%
\contentsline {subsection}{\numberline {14.1.4}Convergence of the difference Riccati equation}{59}{subsection.14.1.4}%
\contentsline {subsubsection}{Theorem 1}{59}{section*.25}%
\contentsline {subsubsection}{Theorem 2}{59}{section*.26}%
\contentsline {subsection}{\numberline {14.1.5}Time invariant filter (predictor)}{59}{subsection.14.1.5}%

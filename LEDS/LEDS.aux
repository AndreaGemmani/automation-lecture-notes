\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is a system?}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Learning modesl from data}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Types of learning}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}fields related to learning from data}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}System identification}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Grey box approach}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Learning steps}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Stochastic Processes}{7}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}stationary stochastic processes}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}cross-correlation and cross-covariance}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}vector stochastic processes}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}gaussian processes}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}white processes}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Stochastic models}{9}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Matlab stuff}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Estmation problem}{11}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Linear regression}{13}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}The Least Squares Method}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Geometrical interpretation of the LS estimate}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Statistical properties of the LS estimator}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}LS estimation fo ARX models}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Identifiablity}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Statistical properties}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}ARX optimal (one step ahead) predictor}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}LS estimation of AR models}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Recursive least squares}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{RLS I}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{RLS II}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Matrix inversion lemma (Woodbury identity)}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{RLS III}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{RLS IV}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Initialization}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Asymptotic behaviour of the RLS algorithm}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Recursive wighted least squares}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{RWLS I}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Prediction error methods}{21}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.1}Identification of ARMAX models}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.2}Statistical properties of PEM estimators}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.0.3}MISO ARX models}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Statistical hypothesis testing}{25}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Model complexity selection and regulariztion}{27}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.1}The F-test}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.2}The final prediction error (FPE) criterion}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.3}Criteria with complexity terms}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.4}Akaike information criterien (AIC)}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Minimum description lenght (MDL) criterion}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}model assesment (validation)}{31}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Whiteness test}{31}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Test of cross-correlation}{32}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Maximum likelihood estimation}{33}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}the gaussian case}{33}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1.1}the Cram√©r-Rao lower bound}{34}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Classification: probabilistic models}{35}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}The Bayes classifier}{35}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Logistic regression}{36}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{How to classify a new input $u(t)$?}{37}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}The gradient descent algorithm}{37}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic gradient descent}{38}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Confusion matrix}{38}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.2}Multiclass problems}{38}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.3}Dealing with nonlinear boundaries}{39}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.4}Linear discriminant analysis}{39}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.5}Gaussian class densities with commmon covariance matrix}{40}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multiclass problem}{40}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.6}Gaussian class denisities with different covariance matrices}{40}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Classification: deterministic models}{41}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.0.1}Separating hyperplanes}{42}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.0.2}the maximum margin classifier}{42}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Constrained optimization problems: the Lagrange multipliers}{42}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Finding the maximum margin classifier by using the Lagrange multipliers}{44}{}\protected@file@percent }
\newlabel{Jderiv}{{12.1}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.0.3}Support vector machine}{45}{}\protected@file@percent }
\gdef \@abspage@last{45}
